2025-09-22 17:38:02,247 - INFO - starting backend service...
2025-09-22 17:38:48,788 - INFO - starting backend service...
2025-09-22 17:43:43,460 - INFO - starting backend service..
2025-09-22 17:43:45,475 - INFO - Starting Frontend service
2025-09-22 17:45:22,125 - INFO - Sending request to backend
2025-09-22 17:45:22,145 - INFO - Recieved request for model : llama-3.3-70b-versatile
2025-09-22 17:45:23,085 - ERROR - Some error occured during response generation
2025-09-22 17:45:23,105 - ERROR - Backend error
2025-09-22 17:45:34,100 - INFO - Sending request to backend
2025-09-22 17:45:34,104 - INFO - Recieved request for model : llama-3.1-8b-instant
2025-09-22 17:45:34,747 - ERROR - Some error occured during response generation
2025-09-22 17:45:34,751 - ERROR - Backend error
2025-09-22 17:47:48,007 - INFO - starting backend service..
2025-09-22 17:47:50,008 - INFO - Starting Frontend service
2025-09-22 17:48:45,248 - INFO - Sending request to backend
2025-09-22 17:48:45,267 - INFO - Received request for model : llama-3.3-70b-versatile
2025-09-22 17:48:46,066 - ERROR - Some error ocuured during reponse generation
2025-09-22 17:48:46,066 - ERROR - Backend error
2025-09-22 17:49:10,477 - INFO - Sending request to backend
2025-09-22 17:49:10,482 - INFO - Received request for model : llama-3.3-70b-versatile
2025-09-22 17:49:11,137 - ERROR - Some error ocuured during reponse generation
2025-09-22 17:49:11,137 - ERROR - Backend error
2025-09-22 17:58:03,281 - INFO - starting backend service..
2025-09-22 17:58:05,286 - INFO - Starting Frontend service
2025-09-22 17:58:31,382 - INFO - Sending request to backend
2025-09-22 17:58:31,398 - INFO - Received request for model : llama-3.3-70b-versatile
2025-09-22 17:58:32,342 - ERROR - Some error ocuured during reponse generation
2025-09-22 17:58:32,342 - ERROR - Backend error
2025-09-22 18:00:24,616 - INFO - Starting backend service..
2025-09-22 18:00:26,617 - INFO - Starting the frontend service
2025-09-22 18:00:57,542 - INFO - Sending request to backend
2025-09-22 18:00:57,556 - INFO - Received request for model: llama-3.3-70b-versatile
2025-09-22 18:01:01,613 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:01:11,494 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:01:12,760 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:01:12,767 - INFO - Successfully got response from AI Agent llama-3.3-70b-versatile
2025-09-22 18:01:12,775 - INFO - Sucesfully recived response from backend
2025-09-22 18:01:46,931 - INFO - Sending request to backend
2025-09-22 18:01:46,934 - INFO - Received request for model: llama-3.1-8b-instant
2025-09-22 18:01:48,123 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:01:48,487 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:01:48,496 - INFO - Successfully got response from AI Agent llama-3.1-8b-instant
2025-09-22 18:01:48,498 - INFO - Sucesfully recived response from backend
2025-09-22 18:08:32,384 - INFO - Starting backend service..
2025-09-22 18:08:34,392 - INFO - Starting the frontend service
2025-09-22 18:09:22,683 - INFO - Starting backend service..
2025-09-22 18:09:24,686 - INFO - Starting the frontend service
2025-09-22 18:11:14,326 - INFO - Sending request to backend
2025-09-22 18:11:14,346 - INFO - Received request for model: llama-3.1-8b-instant
2025-09-22 18:11:18,667 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:11:24,395 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:11:24,583 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-22 18:11:24,583 - INFO - Retrying request to /openai/v1/chat/completions in 7.000000 seconds
2025-09-22 18:11:33,291 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:11:33,297 - INFO - Successfully got response from AI Agent llama-3.1-8b-instant
2025-09-22 18:11:33,305 - INFO - Received response from backend
2025-09-22 18:11:48,557 - INFO - Sending request to backend
2025-09-22 18:11:48,557 - INFO - Received request for model: llama-3.1-8b-instant
2025-09-22 18:11:49,847 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:11:54,652 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-22 18:11:54,652 - INFO - Retrying request to /openai/v1/chat/completions in 13.000000 seconds
2025-09-22 18:12:09,298 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:12:09,339 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-22 18:12:09,339 - INFO - Retrying request to /openai/v1/chat/completions in 38.000000 seconds
2025-09-22 18:12:49,535 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:12:49,545 - INFO - Successfully got response from AI Agent llama-3.1-8b-instant
2025-09-22 18:12:50,908 - INFO - Sending request to backend
2025-09-22 18:12:50,915 - INFO - Received request for model: llama-3.1-8b-instant
2025-09-22 18:12:52,317 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:13:04,540 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-22 18:13:04,540 - INFO - Retrying request to /openai/v1/chat/completions in 23.000000 seconds
2025-09-22 18:13:31,553 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:13:31,596 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-22 18:13:31,596 - INFO - Retrying request to /openai/v1/chat/completions in 44.000000 seconds
2025-09-22 18:14:17,379 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 18:14:17,395 - INFO - Successfully got response from AI Agent llama-3.1-8b-instant
2025-09-22 18:18:55,575 - INFO - Starting backend service..
2025-09-22 18:18:57,575 - INFO - Starting the frontend service
2025-09-22 19:16:32,898 - INFO - Starting backend service..
2025-09-22 19:16:34,899 - INFO - Starting the frontend service
2025-09-22 19:17:04,420 - INFO - Sending request ...
2025-09-22 19:17:04,442 - INFO - Received request for model: llama-3.1-8b-instant
2025-09-22 19:17:06,977 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 19:17:14,241 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 19:17:18,935 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 19:17:18,983 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-09-22 19:17:18,983 - INFO - Retrying request to /openai/v1/chat/completions in 2.000000 seconds
2025-09-22 19:17:22,827 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-22 19:17:22,893 - ERROR - Structured synthesis failed: Got invalid JSON object. Error: Expecting ',' delimiter: line 3 column 2 (char 1042)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
Traceback (most recent call last):
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\venv\Lib\site-packages\langchain_core\utils\json.py", line 189, in parse_and_check_json_markdown
    json_obj = parse_json_markdown(text)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\venv\Lib\site-packages\langchain_core\utils\json.py", line 153, in parse_json_markdown
    return _parse_json(json_str, parser=parser)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\venv\Lib\site-packages\langchain_core\utils\json.py", line 169, in _parse_json
    return parser(json_str)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\venv\Lib\site-packages\langchain_core\utils\json.py", line 126, in parse_partial_json
    return json.loads(s, strict=strict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\anaconda3\Lib\json\__init__.py", line 359, in loads
    return cls(**kw).decode(s)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\anaconda3\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\anaconda3\Lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               ^^^^^^^^^^^^^^^^^^^^^^
json.decoder.JSONDecodeError: Expecting ',' delimiter: line 3 column 2 (char 1042)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\app\core\ai_agent.py", line 246, in get_response_from_ai_agents
    data = fixing_parser.parse(content)  # structured dict
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\venv\Lib\site-packages\langchain\output_parsers\fix.py", line 70, in parse
    return self.parser.parse(completion)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\venv\Lib\site-packages\langchain\output_parsers\structured.py", line 102, in parse
    return parse_and_check_json_markdown(text, expected_keys)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tanay\Desktop\project\MULTIAI_AGENT\venv\Lib\site-packages\langchain_core\utils\json.py", line 192, in parse_and_check_json_markdown
    raise OutputParserException(msg) from e
langchain_core.exceptions.OutputParserException: Got invalid JSON object. Error: Expecting ',' delimiter: line 3 column 2 (char 1042)
For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE 
2025-09-22 19:17:22,916 - INFO - Successfully got response from AI Agent llama-3.1-8b-instant
2025-09-22 19:17:22,918 - INFO - Response received
